{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Install MNIST dataset\n",
    "data_path = os.path.join(os.path.dirname(os.getcwd()), 'datasets')\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, data_home=data_path)\n",
    "print('data:', X.shape, ',', 'labels:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract unique labels\n",
    "unique_labels, counts = np.unique(y, return_counts=True)\n",
    "num_classes = len(unique_labels)\n",
    "print('classes:', unique_labels)\n",
    "print('classes counts:', counts)\n",
    "\n",
    "# Reshape to image\n",
    "X_imgs = X.reshape(-1,28,28)\n",
    "print('X_imgs:', X_imgs.shape)\n",
    "\n",
    "# Random indices\n",
    "idx1, idx2, idx3 = np.random.randint(0, num_classes, 3)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(1, 3, dpi=120)\n",
    "ax[0].imshow(X_imgs[idx1]); ax[1].imshow(X_imgs[idx2]); ax[2].imshow(X_imgs[idx3]);\n",
    "ax[0].axis('off'); ax[1].axis('off'); ax[2].axis('off');\n",
    "ax[0].set_title(str(y[idx1])); ax[1].set_title(str(y[idx2])); ax[2].set_title(str(y[idx3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbors classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a desired number of samples to extract ---------------------\n",
    "n_train_pc = 20 # number of train samples per class\n",
    "n_test_pc = 1 # number of test samples per class\n",
    "\n",
    "n_train = n_train_pc * num_classes\n",
    "n_test = n_test_pc * num_classes\n",
    "\n",
    "# Initialize some variables -----------------------------------------\n",
    "train_data = np.zeros((num_classes,n_train_pc,784))\n",
    "train_labels = np.zeros((num_classes,n_train_pc))\n",
    "\n",
    "test_data = np.zeros((num_classes,n_test_pc,784))\n",
    "test_labels = np.zeros((num_classes,n_test_pc))\n",
    "\n",
    "# Extract balanced data ---------------------------------------------\n",
    "for l_idx, l in enumerate(unique_labels):\n",
    "    idxs = np.squeeze(np.argwhere(y == l)) # where is the current label located in the data?\n",
    "    idxs = np.random.choice(idxs, n_train_pc + n_test_pc, replace=False) # get random samples for the current label\n",
    "    \n",
    "    train_data[l_idx] = X[idxs[:n_train_pc]]\n",
    "    train_labels[l_idx] = y[idxs[:n_train_pc]]\n",
    "    \n",
    "    test_data[l_idx] = X[idxs[n_train_pc:]]\n",
    "    test_labels[l_idx] = y[idxs[n_train_pc:]]\n",
    "    \n",
    "# Ravel train data --------------------------------------------------\n",
    "train_data = train_data.reshape(-1,784)\n",
    "train_labels = np.ravel(train_labels).astype(np.int)\n",
    "\n",
    "# Ravel test data ---------------------------------------------------\n",
    "test_data = test_data.reshape(-1,784)\n",
    "test_labels = np.ravel(test_labels).astype(np.int)\n",
    "\n",
    "# Shuffle train data ------------------------------------------------\n",
    "train_idxs = np.arange(len(train_data))\n",
    "_ = np.random.shuffle(train_idxs)\n",
    "\n",
    "train_data = train_data[train_idxs]\n",
    "train_labels = train_labels[train_idxs]\n",
    "\n",
    "# Shuffle test data -------------------------------------------------\n",
    "test_idxs = np.arange(len(test_data))\n",
    "_ = np.random.shuffle(test_idxs)\n",
    "\n",
    "test_data = test_data[test_idxs]\n",
    "test_labels = test_labels[test_idxs]\n",
    "\n",
    " # Printing ---------------------------------------------------------\n",
    "print('train data:', train_data.shape, ',', 'train labels:', train_labels.shape)\n",
    "print('test data:', test_data.shape, ',', 'test labels:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Euclidean norm (L2 norm) -----------------------------------------------------------\n",
    "squared_diff = (test_data[:,np.newaxis,:] - train_data[np.newaxis, ...]) ** 2\n",
    "sum_squared_diff = np.sum(squared_diff, axis=-1)\n",
    "euclidean_distance = np.sqrt(sum_squared_diff)\n",
    "\n",
    "print('sqaured_diff:', squared_diff.shape, ',', 'sum_squared_diff:', sum_squared_diff.shape, ',',     \n",
    "      'euclidean_distance:', euclidean_distance.shape)\n",
    "\n",
    "# Sort the distances and get the first k closest ones --------------------------------\n",
    "k = 5 # number of votes\n",
    "sort_idxs = np.argsort(euclidean_distance, axis=-1)\n",
    "voting_idxs = sort_idxs[:,:k]\n",
    "\n",
    "print('sort_idxs:', sort_idxs.shape, ',', 'voting_idxs:', voting_idxs.shape)\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Get the winning labels -------------------------------------------------------------\n",
    "k_predicted_labels = train_labels[voting_idxs]\n",
    "print('\\ntest_labels:\\n', test_labels)\n",
    "print('\\nk_predicted_labels:\\n', k_predicted_labels, ', shape:', k_predicted_labels.shape)\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Start voting ----------------------------------------------------------------------\n",
    "votes = np.zeros((n_test,num_classes))\n",
    "test_sample_idxs = np.arange(n_test).reshape(-1,1) # Broadcasting the idxs\n",
    "_ = np.add.at(votes, (test_sample_idxs, k_predicted_labels), 1)\n",
    "print('\\nvotes:\\n', votes, '\\n')\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Get final predictions -------------------------------------------------------------\n",
    "predicted_labels = np.argmax(votes, axis=1)\n",
    "print('predicted_labels:', predicted_labels, '\\noriginal_labels: ', test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN classification using scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors.classification import KNeighborsClassifier \n",
    "\n",
    "kNN = KNeighborsClassifier(n_neighbors=3)\n",
    "kNN.fit(train_data, train_labels)\n",
    "\n",
    "predicted_labels_sklearn = kNN.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_ours = np.sum(predicted_labels == test_labels) # counting number of corret\n",
    "accuracy_ours = num_correct_ours / n_test\n",
    "\n",
    "num_correct_sklearn = np.sum(predicted_labels_sklearn == test_labels) # counting number of correct\n",
    "accuracy_sklearn = num_correct_sklearn / n_test\n",
    "\n",
    "print('num_correct_ours:', num_correct_ours, ',', 'accuracy_ours:', accuracy_ours)\n",
    "print('num_correct_sklearn:', num_correct_sklearn, ',', 'accuracy_sklearn:', accuracy_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA for dimensionality reduction ---------------------------------------\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "pc_train = pca.fit_transform(train_data)\n",
    "print('pc_train:', pc_train.shape)\n",
    "\n",
    "pc_test = pca.transform(test_data)\n",
    "print('pc_test:', pc_test.shape)\n",
    "\n",
    "# Choose and extract classes to visualize -------------------------------------\n",
    "vis_labels = [6,1]\n",
    "\n",
    "vis_train_l1 = pc_train[train_labels == vis_labels[0]]\n",
    "vis_train_l2 = pc_train[train_labels == vis_labels[1]]\n",
    "\n",
    "vis_test_l1 = pc_test[test_labels == vis_labels[0]]\n",
    "vis_test_l2 = pc_test[test_labels == vis_labels[1]]\n",
    "\n",
    "# Visualization ---------------------------------------------------------------\n",
    "fig = plt.figure(dpi=100)\n",
    "\n",
    "# Visualize train samples --------------------\n",
    "plt.scatter(vis_train_l1[:,0], vis_train_l1[:,1], c='b', label='train ' + str(vis_labels[0]))\n",
    "plt.scatter(vis_train_l2[:,0], vis_train_l2[:,1], c='r', label='train ' + str(vis_labels[1])) \n",
    "\n",
    "# Visualize test samples ---------------------\n",
    "plt.scatter(vis_test_l1[:,0], vis_test_l1[:,1], c='b', s=200, marker='+', label='test ' + str(vis_labels[0]))\n",
    "plt.scatter(vis_test_l2[:,0], vis_test_l2[:,1], c='r', s=200, marker='+', label='test ' + str(vis_labels[1])) \n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('1st pc')\n",
    "plt.ylabel('2nd pc')\n",
    "plt.title('first two principal components of train and test data of labels ' + str(vis_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
